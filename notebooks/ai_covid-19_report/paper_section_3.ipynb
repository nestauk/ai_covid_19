{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Geographical analysis\n",
    " * Where is AI research happening?\n",
    " * Who is doing it?\n",
    " * Do we find any differences in the topics that different countries focus on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import random\n",
    "from toolz.curried import *\n",
    "from ast import literal_eval\n",
    "from ai_covid_19.utils.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All arXiv data\n",
    "rxiv = pd.read_csv(f\"{data_path}/processed/rxiv_metadata.csv\",\n",
    "                   dtype={'id':str,'is_ai':bool,'is_covid':bool,'mag_id':str}).pipe(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pd.read_csv(f\"{data_path}/processed/covid_semantic.csv\",\n",
    "                    dtype={'article_id':str}).pipe(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geodata\n",
    "geo = pd.read_csv(f\"{data_path}/processed/rxiv_geo.csv\",\n",
    "                 dtype={'article_id':str,'mag_id':str}).pipe(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a cov df\n",
    "cov = rxiv.query(\"is_covid == True\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the rxiv metadata with the geocoded info, and label those institutions for which we don't have geo data\n",
    "#as unmatched\n",
    "rxiv_geo = pd.merge(rxiv,geo,left_on='id',right_on='article_id')\n",
    "rxiv_geo['institute_country'].fillna('Unmatched',inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Geography of activity\n",
    "\n",
    "##### Country frequencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Focus on recent years\n",
    "rxiv_geo =rxiv_geo.query('year >= 2019')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How active in Covid research are different countries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_freqs = rxiv_geo['institute_country'].value_counts().rename('all_arxiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Country frequencies in different categories (based on the following queries)\n",
    "queries = [\"is_covid == True\",\"is_ai == True\",\"(is_covid ==1) & (is_ai ==True)\"]\n",
    "names = ['covid','ai','covid_ai']\n",
    "\n",
    "all_acts = pd.concat([country_freqs,\n",
    "    pd.concat([rxiv_geo.query(q)['institute_country'].value_counts(\n",
    "    ).rename(n) for n,q in zip(names,queries)],axis=1)],axis=1,sort=True).fillna(0)\n",
    "\n",
    "#Top countries\n",
    "top_countries = list(all_acts.sort_values('covid_ai',ascending=False)[:25].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_activity_long_norm = (100*all_acts.apply(lambda x: x/x.sum()).sort_values('all_arxiv',ascending=False)).loc[\n",
    "    top_countries].reset_index(drop=False).melt(id_vars=['index']).pipe(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean variable names\n",
    "geo_activity_long_norm['variable'] = convert_group(geo_activity_long_norm['variable'])\n",
    "geo_activity_long_norm.rename(columns={'variable':'Category','index':'Country'},inplace=True)\n",
    "geo_activity_long_norm['% of activity'] = make_pc(geo_activity_long_norm['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cluster representation by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are focusing on the covid AI papers \n",
    "cov_geo = rxiv_geo.query(\"(is_ai == True) & (is_covid == True)\").reset_index(drop=False)\n",
    "\n",
    "#Label them with their clusters\n",
    "cluster_mapping = topics.drop_duplicates('article_id').set_index('article_id')['cluster'].to_dict()\n",
    "cov_geo['cluster'] = cov_geo['id'].map(cluster_mapping)\n",
    "\n",
    "#Get top clusters by AI activity\n",
    "top_ai_clusters = topics.drop_duplicates('article_id').groupby(['is_ai','cluster']).size()[True].sort_values(\n",
    "    ascending=False)[:8].index\n",
    "\n",
    "#Cluster frequencies by cluster replacing less common clusters with \"Other\"\n",
    "country_cluster = cov_geo.groupby(['institute_country','cluster']).size().reset_index(name='count')\n",
    "country_cluster['cluster_short'] = [x if x in top_ai_clusters else 'Other' for x in country_cluster['cluster']]\n",
    "\n",
    "#Clean up variable names etc\n",
    "country_cluster['cluster_short'] = clean_cluster(country_cluster['cluster_short'])\n",
    "\n",
    "country_cluster.rename(columns={'institute_country':'Country','cluster_short':'Cluster',\n",
    "                               'count':'Number of papers'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Components of first chart\n",
    "base = (alt.Chart(geo_activity_long_norm)\n",
    "        .encode(\n",
    "            y=alt.Y('Country',sort=top_countries,title=''),\n",
    "            x=alt.X('value',title='% of all activity in category')))\n",
    "\n",
    "points = (base.mark_point(filled=True,\n",
    "                 size=100,opacity=0.75,stroke='black',strokeWidth=1)\n",
    "          .encode(\n",
    "              color=alt.Color('Category'),\n",
    "              shape=alt.Shape('Category',scale=alt.Scale(range=['circle','cross','circle','cross'])),\n",
    "              tooltip = ['Category','Country','% of activity']))\n",
    "\n",
    "points_line = (base.mark_line(strokeWidth=1.5,color='black')\n",
    "               .encode(detail='Country'))\n",
    "\n",
    "rel_line = (base\n",
    "            .transform_filter(alt.datum.variable=='covid_ai')\n",
    "            .mark_line(strokeWidth=1,color='steelblue',opacity=0.8,strokeDash=[2,1])\n",
    "            .encode())\n",
    "\n",
    "#Components of second chart\n",
    "stack = (alt.Chart(country_cluster)\n",
    "         .transform_filter(alt.FieldOneOfPredicate('Country',top_countries))\n",
    "         .mark_bar(stroke='white',strokeWidth=0.1)\n",
    "         .encode(\n",
    "             y=alt.Y('Country',sort=top_countries,title=''),\n",
    "             x='Number of papers',\n",
    "             order=alt.Order('Number of papers',sort='descending'),\n",
    "             tooltip = ['Country','Cluster','Number of papers'],\n",
    "             color=alt.Color('Cluster',\n",
    "                             title='Cluster',\n",
    "                             sort=alt.EncodingSortField('Number of papers','mean','descending'))))\n",
    "\n",
    "comp = (alt.hconcat((points+points_line+rel_line).properties(width=250,height=500),stack.properties(height=500,width=150))\n",
    " .resolve_scale(color='independent',shape='independent'))\n",
    "\n",
    "\n",
    "comp.save(f\"{fig_path}/fig_6.html\")\n",
    "\n",
    "comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evolution of activity\n",
    "\n",
    "Here we compare the evolution of COVID-19 research activity between countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Research papers with geography\n",
    "cov_geo_all = rxiv_geo.query(\"is_covid == 1\").reset_index(drop=False)\n",
    "cov_geo_all['date'] = pd.to_datetime(cov_geo_all['created'])\n",
    "\n",
    "#Calculate trends focusing on top countries\n",
    "cov_geo_trend = cov_geo_all.query('year ==2020').groupby(\n",
    "    ['institute_country','is_ai','date']).size().loc[top_countries[:12]].reset_index(name='count')\n",
    "cov_geo_trend['is_ai'] = convert_ai(cov_geo_trend['is_ai'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cumulative activity by year\n",
    "\n",
    "When do different countries reach a critical mass of activity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate using the geotrend data\n",
    "cov_geo_cumul = (cov_geo_trend\n",
    "                 .pivot_table(\n",
    "                     index='date',columns='institute_country',values='count',aggfunc='sum').fillna(0)\n",
    "                 .rolling(window=5)\n",
    "                 .mean().dropna().cumsum())\n",
    "\n",
    "#Calculate shares\n",
    "cov_geo_shares = cov_geo_cumul/cov_geo_cumul.iloc[-1]\n",
    "\n",
    "country_date = {'country':[],'first_date':[]}\n",
    "\n",
    "#Extract the date when the country went over 25% of its total of activity\n",
    "for c in cov_geo_shares.columns:\n",
    "    first_date = (cov_geo_shares.loc[cov_geo_shares[c]>0.25]).index[0]\n",
    "    country_date['country'].append(c)\n",
    "    country_date['first_date'].append(first_date)\n",
    "\n",
    "geo_dates_df = pd.DataFrame(country_date).sort_values('first_date',ascending=True)\n",
    "\n",
    "countries_ordered = list(geo_dates_df['country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_chart = (alt.Chart(cov_geo_trend).\n",
    "               mark_line(opacity=0.9)\n",
    "               .transform_window(m='mean(count)',frame=[-3,3],groupby=['institute_country','is_ai'])\n",
    "               .encode(\n",
    "                   x='date',\n",
    "                   y=alt.Y('m:Q',\n",
    "                           title=['Research','participations']),\n",
    "                   color=alt.Color('is_ai:N',sort=['AI','Not AI']),\n",
    "                   facet=alt.Facet('institute_country',columns=4,\n",
    "                                   title='Country',\n",
    "                                   sort = countries_ordered\n",
    "                                   #sort=alt.EncodingSortField('count','sum',order='descending'))\n",
    "                                  ))\n",
    "               .properties(width=100,height=85)\n",
    "               .resolve_scale(y='independent'))\n",
    "\n",
    "\n",
    "trend_chart.save(f\"{fig_path}/fig_7.html\")\n",
    "\n",
    "trend_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
