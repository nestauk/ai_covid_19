{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Quality and track record\n",
    "\n",
    "* What are the levels of quality (impact) of Covid AI research papers?\n",
    "* What are the levels of experience of AI researchers focusing on Covid?\n",
    "* How does the above differ between COVID research clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import altair as alt\n",
    "from toolz.curried import *\n",
    "from ast import literal_eval\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from ai_covid_19.utils.utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def citation_distr(_vector,bins=[0,1,2,3,5,10,20,100,1000]):\n",
    "    '''Bins citations according to intervals\n",
    "    \n",
    "    Args:\n",
    "        _vector: distribution of citations\n",
    "        bins: (list) intervals for binning\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    bins_ = bins.copy()\n",
    "    \n",
    "    cut = pd.cut(_vector,bins=bins_,right=False,include_lowest=True)\n",
    "    \n",
    "    out = cut.value_counts(normalize=True)\n",
    "    out.index= ['_'.join([x.strip() for x in re.sub('\\[|\\)','',str(inter)).split(',')]) for inter in out.index]\n",
    "    \n",
    "    return(out)\n",
    "\n",
    "def get_author_profile(x):\n",
    "    '''Extract an author track record\n",
    "    \n",
    "    Args:\n",
    "        x (df) is a df with the publications that the author has been involved in\n",
    "    Returns a series with the number of papers she has authored, her citation mean and median and her\n",
    "    experience (number of years she has been present in the data)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    stats = [len(x),\n",
    "             x['citation_count'].median(),\n",
    "             x['citation_count'].mean(),\n",
    "             2020-x['year'].min()]\n",
    "    return(pd.Series(stats,\n",
    "                     index=['paper_n','citation_median','citation_mean','experience']))\n",
    "\n",
    "\n",
    "def make_mean_comp(table,var_name,table_name):\n",
    "    '''Creates a table to compare means\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    t_l = table.reset_index(drop=False).melt(id_vars=var_name)\n",
    "    t_l.rename(columns={var_name:'category','variable':'statistic'},inplace=True)\n",
    "    t_l['variable'] = [f\"{var_name}: {b}\" for b in t_l['category']]\n",
    "    t_l['table'] = table_name\n",
    "    return(t_l)\n",
    "\n",
    "def get_tests_table(table,variable_name,test=ttest_ind):\n",
    "    '''P\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    res = {}\n",
    "\n",
    "    for x in stat_names:\n",
    "\n",
    "        t_1 = test(table.loc[table[variable_name]==True][x],\n",
    "                        table.loc[table[variable_name]==False][x])\n",
    "\n",
    "        res[x] = t_1[1]\n",
    "    return(res)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All arXiv data\n",
    "rxiv = pd.read_csv(f\"{data_path}/processed/rxiv_metadata.csv\",dtype={'id':str,\n",
    "                                                                    'is_ai':bool,'is_covid':bool}).pipe(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the covid df\n",
    "cov = rxiv.query(\"is_covid == True\").reset_index(drop=True).pipe(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a paper-cluster membership lookup\n",
    "cluster_lookup = pd.read_csv(\n",
    "    f\"{data_path}/processed/covid_semantic.csv\",dtype={'article_id':str}).drop_duplicates(\n",
    "    'article_id').set_index('article_id')['cluster'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Covid vs non covid citations\n",
    "\n",
    "How do the levels of citations for Covid and non-Covid research compare?\n",
    "\n",
    "#### Cited / non-cited comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxiv_2020 = rxiv.query('year == 2020')\n",
    "\n",
    "rxiv_2020['cluster'] = rxiv['id'].map(cluster_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxiv_2020.groupby(['is_covid','is_ai'])['citation_count'].mean().reset_index(drop=False).pivot_table(\n",
    "index='is_covid',columns='is_ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit_groups = rxiv_2020.groupby(\n",
    "    ['is_covid','is_ai','article_source'])['citation_count'].mean().reset_index()\n",
    "\n",
    "alt.Chart(cit_groups).mark_bar().encode(x='is_covid:N',y='citation_count',\n",
    "                                        column='is_ai:N',\n",
    "                                        row='article_source').properties(height=100,width=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison of paper with at least one citation: AI vs non AI by article source\n",
    "rxiv_2020.assign(\n",
    "    has_cit = lambda x: x['citation_count']>0).groupby(\n",
    "    ['article_source','is_covid'])['has_cit'].mean().reset_index(name='share').pivot_table(\n",
    "    index='article_source',columns='is_covid',values='share').assign(rep = lambda x: x[1]/x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full distribution of citations by source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_lookup = {'0_1':'0: 0-1', '100_1000':'7: >100', '10_20':'5: 10-20', '1_2':'1: 1-2', \n",
    "              '20_100':'6: 20-100', '2_3':'2: 2-3', \n",
    "              '3_5':'3: 3-5', '5_10':'4: 5-10'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxiv_cit_distrs = rxiv_2020.groupby(\n",
    "    ['is_covid','is_ai','article_source'])['citation_count'].apply(lambda x:\n",
    "                                                                  citation_distr(x)).reset_index(\n",
    "    drop=False).pipe(preview)\n",
    "\n",
    "rxiv_cit_distrs['int_sorted'] = rxiv_cit_distrs['level_3'].map(int_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up the variable names and categories\n",
    "rxiv_cit_distrs['is_covid'],rxiv_cit_distrs['is_ai'],rxiv_cit_distrs['article_source'] = [\n",
    "    func(rxiv_cit_distrs[var]) for func,var in zip(\n",
    "        [convert_covid,convert_ai,convert_source],['is_covid','is_ai','article_source'])]\n",
    "\n",
    "rxiv_cit_distrs['citation_count'] = 100*rxiv_cit_distrs['citation_count']\n",
    "rxiv_cit_distrs['% of papers'] = make_pc(rxiv_cit_distrs['citation_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chart\n",
    "b = (alt\n",
    " .Chart(rxiv_cit_distrs)\n",
    " .mark_bar(stroke='black',strokeWidth=0.5)\n",
    " .encode(x=alt.X('is_covid:N',title=''),\n",
    "         y=alt.Y('citation_count',title='% of papers'),\n",
    "         color=alt.Color(\n",
    "             'int_sorted:O',scale=alt.Scale(scheme='orangered'),title=['Number of','citations']),\n",
    "         column=alt.Column('article_source',title='Source'),\n",
    "         row=alt.Row('is_ai:N',title=''),\n",
    "            tooltip=['% of papers']))\n",
    "\n",
    "b = b.properties(height=77,width=100).resolve_scale(color='shared')\n",
    "\n",
    "b.save(f\"{fig_path}/fig_10.html\")\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Citations by cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Focus on covid papers for which we have cluster information\n",
    "rxiv['cluster'] = rxiv['id'].map(cluster_lookup)\n",
    "cov = rxiv.query('is_covid==True').reset_index(drop=True).dropna(axis=0,subset=['cluster'])\n",
    "\n",
    "#List of top 12 clusters in terms of AI publications\n",
    "top_ai_clusters = list(cov.query('is_ai==1')['cluster'].value_counts().sort_values(ascending=False)[:12].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get citations for papers in different clusters\n",
    "cit_sorted = clean_cluster([x for x in cov.groupby('cluster')['citation_count'].mean().sort_values(ascending=False).index if\n",
    "              x in top_ai_clusters])\n",
    "#Clean variable names\n",
    "cov['cluster'] = clean_cluster(cov['cluster'])\n",
    "\n",
    "\n",
    "top_clust_cov = cov.loc[[x in cit_sorted for x in cov['cluster']]]\n",
    "top_clust_cov['rank'] = top_clust_cov['cluster'].map({c:n for n,c in enumerate(cit_sorted)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_clust_cov['cluster'] = clean_cluster(top_clust_cov['cluster'])\n",
    "top_clust_cov['is_ai'] = convert_ai(top_clust_cov['is_ai'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate citation means\n",
    "citation_means = top_clust_cov.groupby(['is_ai','cluster'])['citation_count'].mean().apply(\n",
    "    lambda x: np.round(x,2)).reset_index(name='Citation mean')\n",
    "\n",
    "#Merge with the cluster info\n",
    "\n",
    "top_clust_cov_2 = pd.merge(top_clust_cov,citation_means,\n",
    "                          left_on=['is_ai','cluster'],right_on=['is_ai','cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "\n",
    "for n,c in enumerate(cit_sorted):\n",
    "    \n",
    "    l1 = (alt.Chart(top_clust_cov_2)\n",
    "         .transform_filter(alt.datum.cluster==c)\n",
    "         .mark_point(opacity=0.5,stroke='black',strokeWidth=2,filled=True)\n",
    "         .encode(x=alt.X('is_ai:N',title=''),\n",
    "                 y=alt.Y('citation_count:Q',title=['Number','of citations']),\n",
    "                 size=alt.Size('count()',\n",
    "                               scale=alt.Scale(range=[0,100],type='log'),\n",
    "                              title=['Number', 'of publications']),\n",
    "                               color=alt.Color('is_ai:N',title='Category'),\n",
    "                tooltip=['Citation mean:Q']))\n",
    "\n",
    "    l2 = (alt.Chart(top_clust_cov_2)\n",
    "          .transform_filter(alt.datum.cluster==c)\n",
    "          .mark_line(strokeWidth=1,strokeDash=[1,1])\n",
    "          .encode(x='is_ai:N',y='citation_count:Q',detail='is_ai:N',color='is_ai:N'))\n",
    "    \n",
    "    l2 = (alt.Chart(top_clust_cov_2)\n",
    "          .transform_filter(alt.datum.cluster==c)\n",
    "          .mark_tick(strokeWidth=1,opacity=0.7)\n",
    "          .encode(x='is_ai:N',y='citation_count:Q',\n",
    "                  color='is_ai:N',tooltip=['Citation mean:Q']))\n",
    "\n",
    "    ch = (l1+l2).properties(height=100,width=150,title=c)\n",
    "    \n",
    "    out.append(ch)\n",
    "    \n",
    "out_threes = [out[:3],out[3:6],out[6:9],out[9:12]]\n",
    "\n",
    "#Arrange things so they fit in a page\n",
    "r = []\n",
    "\n",
    "for p in out_threes:\n",
    "    \n",
    "    r.append(alt.hconcat(*p))\n",
    "    \n",
    "fin_fig = alt.vconcat(*r)\n",
    "\n",
    "fin_fig.save(f\"{fig_path}/fig_11.html\")\n",
    "\n",
    "fin_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate citation means by group: How often are AI means above or below non-A)\n",
    "\n",
    "citation_means = rxiv_2020.query('is_covid==True').groupby(['cluster','is_ai'])[\n",
    "    'citation_count'].mean().reset_index(name='statistic').pivot_table(index='cluster',columns='is_ai',\n",
    "                                                                      values='statistic').loc[\n",
    "    top_ai_clusters[:10]].sort_values(1,ascending=False)\n",
    "\n",
    "citation_means['status'] = [row[1]>=row[0] for _id,row in citation_means.iterrows()]\n",
    "\n",
    "citation_means['status'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Track record of authors\n",
    "\n",
    "Here we compare the publication records of authors focusing on different COVID-19 topics and in different categories (eg AI vs non AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Focus on papers with authors\n",
    "rxiv_auth = rxiv.dropna(axis=0,subset=['mag_authors'])\n",
    "\n",
    "#Extract author ids from author credentials dict\n",
    "#First we need to parse the mag_authors json\n",
    "rxiv_auth['mag_authors'] = rxiv_auth['mag_authors'].apply(literal_eval)\n",
    "\n",
    "rxiv_auth['author_id'] = [[x['author_id'] for x in p] for p in rxiv_auth['mag_authors']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the lookup between papers and authors\n",
    "paper_author_lookup = rxiv_auth[['id','author_id']].explode('author_id').pipe(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find authors with at least one covid paper\n",
    "covid_paper_ids = set(cov['id'])\n",
    "ai_paper_ids = set(rxiv.query('is_ai == 1')['id'])\n",
    "covid_ai_paper_ids = set(cov.query('is_ai == 1')['id'])\n",
    "\n",
    "#Get lists of authors with at least one covid, ai, covid ai paper\n",
    "cov_paper_auths,ai_paper_auths,covid_ai_paper_auths = [set(\n",
    "    paper_author_lookup.loc[[x in ids for x in paper_author_lookup['id']]]['author_id']) for \n",
    "                                                     ids in [covid_paper_ids,ai_paper_ids,\n",
    "                                                             covid_ai_paper_ids]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with xiv and focus on covid authors\n",
    "trajectories = rxiv.merge(paper_author_lookup,left_on='id',right_on='id').dropna(\n",
    "    axis=0,subset=['author_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covid and non-Covid authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Focus on non Covid publications in recent years\n",
    "trajectories_non_covid = trajectories.loc[[x not in covid_paper_ids \n",
    "                                                               for x in trajectories['id']]]\n",
    "trajectories_recent = trajectories_non_covid.query(\"(year == 2018) | (year == 2019)\")\n",
    "\n",
    "author_cluster = trajectories.groupby('cluster')['author_id'].apply(lambda x: set(list(x)))\n",
    "\n",
    "#Extract researcher profiles (focusing on those with publications in 2019)\n",
    "#Note - this takes some time to run\n",
    "author_profile = trajectories_recent.groupby('author_id').apply(lambda x: get_author_profile(x))\n",
    "\n",
    "#Label authors with whether they have one covid, one ai or one covid_ai paper\n",
    "author_profile['has_cov'], author_profile['has_ai'],author_profile['has_covid_ai'] = [\n",
    "    author_profile.index.isin(group) for group in [cov_paper_auths,ai_paper_auths,covid_ai_paper_auths]]\n",
    "\n",
    "#Label them wih the clusters where they have published\n",
    "author_profile['cluster'] = [[cid for cid,cgr in author_cluster.iteritems() if auth in cgr] for\n",
    "                             auth in author_profile.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we compare the statistics for papers in various categories\n",
    "stat_names = ['paper_n','citation_mean','citation_median','experience']\n",
    "\n",
    "#Create a bunch of tables that compare mean citations for ait\n",
    "cov_comp  = author_profile.groupby('has_cov')[stat_names].mean()\n",
    "ai_comp  = author_profile.query('has_ai == True').groupby('has_covid_ai')[stat_names].mean()\n",
    "cov_ai_comp  = author_profile.query('has_cov == True').groupby('has_covid_ai')[stat_names].mean()\n",
    "\n",
    "tables = [cov_comp,ai_comp,cov_ai_comp] \n",
    "var_names = ['has_cov','has_covid_ai','has_covid_ai']\n",
    "table_names = ['all_papers','all_ai_papers','all_covid_papers']\n",
    "\n",
    "all_tables = pd.concat([make_mean_comp(t,var,name) for t,var,name in zip(tables,var_names,table_names)])\n",
    "\n",
    "all_tables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we test statistical significance of differences in means between the variables\n",
    "test_df = pd.DataFrame([get_tests_table(table,variable_name,mannwhitneyu) for table,variable_name in\n",
    "        zip([author_profile,\n",
    "             author_profile.query('has_ai == True'),\n",
    "             author_profile.query('has_cov == True')],\n",
    "            ['has_cov','has_covid_ai','has_covid_ai'])],\n",
    "                     index=['all_papers','all_ai_papers','all_covid_papers'])\n",
    "\n",
    "#Turn into a long df so we can merge with the means table \n",
    "test_df_long = test_df.reset_index(drop=False).melt(id_vars='index',\n",
    "                                                    var_name='statistic',\n",
    "                                                    value_name='significant')\n",
    "test_df_long['significant'] = test_df_long['significant']<0.05\n",
    "\n",
    "all_tables_tests = pd.merge(all_tables,test_df_long,left_on=['statistic','table'],\n",
    "                           right_on=['statistic','index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tidy up variable names for the chart\n",
    "\n",
    "\n",
    "var_names = ['statistic','variable','table','index','significant']\n",
    "\n",
    "#Lookups between variables\n",
    "stat_lookup = {'paper_n':'Number of papers','citation_mean':'Citation (mean)',\n",
    "              'citation_median':'Citation (median)','experience':'Experience'}\n",
    "\n",
    "var_lookup = {'has_cov: False':'Not COVID-19','has_cov: True':'COVID-19',\n",
    "             'has_covid_ai: True': 'COVID-19 and AI','has_covid_ai: False': 'COVID-19 and not AI'}\n",
    "\n",
    "table_lookup = {'all_papers':'All research','all_ai_papers':'AI research',\n",
    "               'all_covid_papers':'COVID-19 research'}\n",
    "\n",
    "significant = {True:'Significant',False:'Insignificant'}\n",
    "\n",
    "#Convert variables using the lookups\n",
    "for v,l in zip(var_names,[stat_lookup,var_lookup,table_lookup,table_lookup,significant]):\n",
    "    all_tables_tests[v] = convert_var(all_tables_tests[v],l)\n",
    "\n",
    "#Create a rounded variable for tooltops\n",
    "all_tables_tests['value_label'] = [str(np.round(x,2)) for x in all_tables_tests['value']]\n",
    "\n",
    "#We are not interested in the experience variable (we are focusing on authors with recent publications)\n",
    "all_tables_tests = all_tables_tests.query(\"statistic != 'Experience'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make chart\n",
    "mean_comp = (alt.Chart(all_tables_tests)\n",
    "             .mark_bar(height=15,stroke='black')\n",
    "             .encode(\n",
    "                 y=alt.Y('variable:N',title=''),\n",
    "                 x=alt.X('value:Q',title='Score'),\n",
    "                 color=alt.Color('significant',\n",
    "                                 scale=alt.Scale(range=['lightpink','steelblue']),title='Significance'),\n",
    "                 column=alt.Column('statistic:N'),\n",
    "                 row=alt.Row('table:N',\n",
    "                             sort=['All research','AI research','COVID-19 reesearch'],\n",
    "                             title='Corpus'),\n",
    "                 tooltip=['value_label'])\n",
    "             .resolve_scale(y='independent',x='shared').properties(height=70,width=70))\n",
    "\n",
    "mean_comp.save(f\"{fig_path}/fig_13.html\")\n",
    "\n",
    "mean_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AI and non-AI authors between clusters\n",
    "\n",
    "In this case we want to consider the full trajectory of researchers working in Covid, not just the most recent two years, but excluding Covid papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Focus on Covid authors in recent years\n",
    "trajectories_covid_authors = trajectories_non_covid.loc[trajectories.author_id.isin(cov_paper_auths)]\n",
    "trajectories_covid_authors = trajectories_covid_authors.query('(year > 2017) & (year <2020)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract author profile\n",
    "author_profile_cov = trajectories_covid_authors.groupby('author_id').apply(lambda x: get_author_profile(x))\n",
    "#Label authors with whether they have one covid, one ai or one covid_ai paper\n",
    "author_profile_cov['has_covid_ai'] = author_profile_cov.index.isin(covid_ai_paper_auths)\n",
    "#Label them wih the clusters where they have published\n",
    "author_profile_cov['cluster'] = [[cid for cid,cgr in author_cluster.iteritems() if auth in cgr] for\n",
    "                             auth in author_profile_cov.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author profile in cluster\n",
    "\n",
    "#Explode the dataframe by the author cluster\n",
    "author_profile_exploded = author_profile_cov.explode('cluster')\n",
    "\n",
    "#Calculate means for each cluster\n",
    "prof_clust = author_profile_exploded.groupby(\n",
    "    ['cluster','has_covid_ai'])[stat_names].mean().loc[top_ai_clusters[:10]].reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate statistical significance of differences\n",
    "\n",
    "cluster_test_df = pd.DataFrame([get_tests_table(author_profile_exploded.loc[author_profile_exploded['cluster']==x],\n",
    "                                                        'has_covid_ai',mannwhitneyu) for\n",
    "                               x in top_ai_clusters[:10]],index=top_ai_clusters[:10])\n",
    "\n",
    "cluster_test_long = cluster_test_df.reset_index(drop=False).melt(id_vars='index',var_name='statistic',\n",
    "                                            value_name='significance')\n",
    "\n",
    "cluster_test_long['significance_thres'] = ['p < 0.01' if x<0.01 else 'p < 0.05' if x<0.05 else 'p < 0.1' if x<0.1 \n",
    "                                           else 'p > 0.1' for\n",
    "                                    x in cluster_test_long['significance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make charts\n",
    "charts = []\n",
    "\n",
    "for v in ['paper_n','citation_mean','citation_median']:\n",
    "    \n",
    "    d = prof_clust[['cluster','has_covid_ai',v]]\n",
    "    \n",
    "    d['has_covid_ai'] = convert_ai(d['has_covid_ai'])\n",
    "    \n",
    "    s = cluster_test_long.loc[cluster_test_long['statistic']==v].set_index(\n",
    "        'index')['significance_thres'].to_dict()\n",
    "    \n",
    "    d['significance_thres'] = d['cluster'].map(s)\n",
    "    d['cluster'] = clean_cluster(d['cluster'])\n",
    "    \n",
    "    d[f'Mean {stat_lookup[v]}'] = [str(np.round(x,2)) for x in d[v]]\n",
    "        \n",
    "    c = (alt.Chart(d)\n",
    "         .mark_bar(height=10,stroke='black',strokeWidth=1,strokeOpacity=1)\n",
    "         .encode(y=alt.Y('has_covid_ai',title=None),\n",
    "                 x=alt.X(v,title=stat_lookup[v]),\n",
    "                 color=alt.Color('has_covid_ai',title='Category'),\n",
    "                 opacity=alt.Opacity('significance_thres:N',scale=alt.Scale(range=[0.3,1]),\n",
    "                                    title='Significance',\n",
    "                                    sort=['p > 0.1','p < 0.1','p < 0.05','p < 0.01']),\n",
    "                 row=alt.Row('cluster',\n",
    "                             sort=alt.EncodingSortField(v,'max',order='descending')),\n",
    "                tooltip=[f'Mean {stat_lookup[v]}']))\n",
    "    \n",
    "    charts.append((c).properties(height=40,width=40,title=stat_lookup[v]))\n",
    "    \n",
    "cluster_comp = alt.hconcat(*charts).configure_axis(grid=True)\n",
    "\n",
    "cluster_comp.save(f\"{fig_path}/fig_14.html\")\n",
    "\n",
    "cluster_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in stat_names:\n",
    "    \n",
    "    \n",
    "    piv = prof_clust.pivot_table(index='cluster',columns='has_covid_ai',values=x)\n",
    "    \n",
    "    print(x)\n",
    "    print(np.mean(piv[False]>piv[True]))\n",
    "    \n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
