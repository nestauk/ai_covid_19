{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Knowledge base\n",
    "\n",
    "* On what topics do AI researchers draw on?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from itertools import chain\n",
    "from scipy.stats import entropy, zscore\n",
    "from data_getters.inspector import get_schemas\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "from ai_covid_19.utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(set_1,set_2):\n",
    "    ov = 100*len(set_1.intersection(set_2))/len(set_1.union(set_2))\n",
    "    return(ov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(_list,freq=False,norm=True):\n",
    "    \n",
    "    flat = [x for el in _list for x in el]\n",
    "    \n",
    "    if freq==False:\n",
    "        return flat\n",
    "    else:\n",
    "        return pd.Series(flat).value_counts(normalize=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxiv = pd.read_csv(f\"{data_path}/processed/rxiv_metadata.csv\",\n",
    "                   dtype={'id':str,'is_ai':bool,'is_covid':bool}).pipe(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pd.read_csv(f\"{data_path}/processed/covid_semantic.csv\",\n",
    "                    dtype={'article_id':str}).pipe(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_fos = pd.read_csv(f\"{data_path}/processed/mag_fos.csv\").pipe(preview).dropna(axis=0,\n",
    "                                                                                                 subset=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{data_path}/processed/ai_article_mag_info.json\",'r') as infile:\n",
    "    article_mag = json.load(infile)\n",
    "    \n",
    "with open(f\"{data_path}/processed/citation_lookup.json\",'r') as infile:\n",
    "    citation_lookup = json.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Process fields of study info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a lookup between levels and names (lowercased)\n",
    "mag_fos['name_l'] = [x.lower() for x in mag_fos['name']]\n",
    "mag_levels = mag_fos.groupby('level')['name_l'].apply(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert mag ids to strs in the corpus df\n",
    "topics_ = topics.dropna(axis=0,subset=['mag_id'])\n",
    "\n",
    "topics_['mag_id'] = [str(int(x)) for x in topics_['mag_id']]\n",
    "\n",
    "cov_short = topics_[['article_id','mag_id','cluster','is_ai']].drop_duplicates(\n",
    "    'mag_id').reset_index(drop=True)\n",
    "\n",
    "#This gives us all the cited papers by a paper in the covid dataset\n",
    "cov_short['cited'] = cov_short['mag_id'].map(citation_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract field of study sets for each element in cited\n",
    "cov_cits = cov_short.dropna(axis=0,subset=['cited'])\n",
    "\n",
    "cov_cits['fos_cited'] = [flatten([article_mag[x]['fields_of_study'] if 'fields_of_study' in \n",
    "                          article_mag[x].keys() else [] for x in cit if x in article_mag.keys()]) for cit in cov_cits['cited']]\n",
    "\n",
    "cov_cits['fos_cited_unique'] = [set(x) for x in cov_cits['fos_cited']]\n",
    "\n",
    "cov_cits['fos_cited_l0'] = [[x for x in cited if x in mag_levels[0]] for cited in cov_cits['fos_cited']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Distribution of citations at level 1\n",
    "\n",
    "What is the distribution of citations to high level disciplines inside AI vs outside?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_cits = cov_cits.groupby('is_ai')['fos_cited_l0'].apply(lambda x: 100*flatten(x,freq=True)).reset_index(\n",
    "    drop=False).pipe(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean variable names\n",
    "l1_cits['Category'] = convert_ai(l1_cits['is_ai'])\n",
    "l1_cits['level_1'] = [x.capitalize() for x in l1_cits['level_1']]\n",
    "l1_cits['value_label'] = make_pc(l1_cits['fos_cited_l0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = (alt\n",
    "        .Chart(l1_cits)\n",
    "        .mark_bar(opacity=0.5,stroke='black')\n",
    "        .encode(\n",
    "            y=alt.Y('level_1',sort=alt.EncodingSortField('fos_cited_l0','sum',order='descending'),\n",
    "                   title='Field of Study'),\n",
    "            x=alt.X('fos_cited_l0',stack=None,title=['% of citations by papers','in category']),\n",
    "            color='Category',\n",
    "            tooltip=['Category','level_1','value_label']))\n",
    "\n",
    "bar_2 = bar.properties(height=300,width=400)\n",
    "\n",
    "bar_2.save(f\"{fig_path}/fig_8.html\")\n",
    "\n",
    "bar_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Over or underrepresentation of citations in a topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit_rep = l1_cits.pivot_table(index='level_1',columns='Category',values='fos_cited_l0').assign(\n",
    "    prop=lambda x: x['AI']/x['Not AI']).dropna()\n",
    "cit_rep.loc[['Medicine','Biology','Computer science']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overlap in citations between topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit_sets = cov_cits.groupby('is_ai')['cited'].apply(lambda x: set(chain(*list(x))))\n",
    "\n",
    "print(str(np.round(100*len(cit_sets[True].intersection(cit_sets[False]))/len(cit_sets[True].union(cit_sets[False])),\n",
    "                   2))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of citations at level 3\n",
    "\n",
    "Here we compare citatins between AI / non AI research at a higher level of field of study granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_cits['fos_cited_l1'] = [[x for x in cited if x in mag_levels[1]] for cited in cov_cits['fos_cited']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to focus on the most cited topics within the corpus\n",
    "top_50_topics = list(flatten(cov_cits['fos_cited_l1'],freq=True)[:30].index)\n",
    "\n",
    "ai_clusters_sorted = list(cov_short.query('is_ai==True')['cluster'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This extracts the distribution of citations per category / cluster\n",
    "cov_fos1 = cov_cits.groupby(\n",
    "    ['is_ai','cluster'])['fos_cited_l1'].apply(lambda x: 100*flatten(list(x),freq=True)).reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a lookup\n",
    "fos_0_lu = {r['id']:r['name'] for idx,r in mag_fos.query(\"level == 0\").iterrows()}\n",
    "\n",
    "fos_1_to_0_lu = {fos_0_lu[[int(x) for x in pars.split(',')][0]] for pars in mag_fos.loc[mag_fos['level']==1]['parent_ids']}\n",
    "\n",
    "name_lookup = {r['name'].lower():fos_0_lu[int(r['parent_ids'].split(',')[0])] for rid,r in mag_fos.loc[mag_fos['level']==1].iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add higher level discipline to table\n",
    "cov_fos1['discipline'] = cov_fos1['level_2'].map(name_lookup)\n",
    "\n",
    "#Some cleaning of variable names etc for the chart\n",
    "cov_fos1['Cluster'] = clean_cluster(cov_fos1['cluster'])\n",
    "cov_fos1['Subfield'] = [x.capitalize() for x in cov_fos1['level_2']]\n",
    "cov_fos1['% of citations in Cluster'] = make_pc(cov_fos1['fos_cited_l1'])\n",
    "top_50_cap = [x.capitalize() for x in top_50_topics]\n",
    "clean_clust = clean_cluster(ai_clusters_sorted[:10])\n",
    "cov_fos1['cluster'] = clean_cluster(cov_fos1['Cluster'])\n",
    "cov_fos1['is_ai'] = convert_ai(cov_fos1['is_ai'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_ch = (alt.Chart(cov_fos1)\n",
    "            .transform_filter(alt.FieldOneOfPredicate('Subfield',top_50_cap))\n",
    "            .transform_filter(alt.FieldOneOfPredicate('cluster',clean_clust))\n",
    "            .mark_point(filled=True,strokeWidth=0.7,stroke='black')\n",
    "            .encode(y=alt.Y('is_ai:N',title=''),\n",
    "                    x=alt.X('Subfield:N',sort=top_50_cap,title='Subfield:N'),\n",
    "                    size=alt.Size('fos_cited_l1',title=['% of all citations','in cluster']),\n",
    "                    color=alt.Color('discipline:N',title='Discipline'),\n",
    "                    tooltip = ['Cluster','Subfield','discipline','% of citations in Cluster'],\n",
    "                    row=alt.Row('Cluster',sort=clean_clust,title='Cluster'))).properties(width=500)\n",
    "\n",
    "point_ch = point_ch.configure_axis(grid=True)\n",
    "\n",
    "point_ch.save(f\"{fig_path}/fig_9.html\")\n",
    "\n",
    "point_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlaps between AI / non-AI citations across clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a set of cited references per cluster and AI / non AI pair\n",
    "cit_cluster_sets = cov_cits.groupby(['cluster','is_ai'])['cited'].apply(lambda x: set(chain(*list(x))))\n",
    "\n",
    "p = {}\n",
    "\n",
    "for x in set(cov_cits['cluster']):\n",
    "    rel = cit_cluster_sets[x]\n",
    "    try:\n",
    "        p[x] = overlap(rel[True],rel[False])\n",
    "    except:\n",
    "        p[x] = np.nan\n",
    "        \n",
    "ov = pd.Series(p).sort_values(ascending=False).reset_index(name='citation_overlap')\n",
    "ov['index'] = clean_cluster(ov['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = (alt.Chart(ov)\n",
    "     .mark_bar(width=9)\n",
    "     .encode(x=alt.X('index',sort=alt.EncodingSortField('citation_overlap',order='descending')),\n",
    "             y=alt.Y('citation_overlap')))\n",
    "\n",
    "r = (alt.Chart(ov)\n",
    "     .transform_calculate(mean='3.7')\n",
    "     .mark_rule(color='red',strokeDash=[1,1])\n",
    "     .encode(\n",
    "         y=alt.Y('mean:Q',title=['% reference overlap','between AI and non-AI papers'])))\n",
    "\n",
    "fin = (b+r).properties(height=200)\n",
    "\n",
    "fin.save(f\"{fig_path}/fig_10.html\")\n",
    "\n",
    "fin"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
